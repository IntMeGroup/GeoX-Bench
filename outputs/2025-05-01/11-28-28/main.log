[2025-05-01 11:28:29,117][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 12:00:41,530][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 12:01:12,210][qwen_vl_utils.vision_process][INFO] - set VIDEO_TOTAL_PIXELS: 50176
[2025-05-01 12:30:57,940][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 12:31:21,433][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-05-01 12:31:21,532][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-05-01 13:43:49,010][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 13:44:13,701][transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v][INFO] - learnable separator enabled for hd transform, hd_transform_order = sub_glb
[2025-05-01 14:41:32,567][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 14:42:17,766][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-05-01 15:20:47,942][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-05-01 15:21:11,431][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-05-01 15:21:11,431][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-05-01 15:21:11,431][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-05-01 15:21:11,432][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-05-01 15:21:11,440][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-05-01 15:21:11,440][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-05-01 15:21:11,440][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-05-01 15:21:11,440][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-05-01 15:21:12,009][transformers_modules.InternVL3-8B.modeling_intern_vit][INFO] - Discovered apex.normalization.FusedRMSNorm - will use it instead of InternRMSNorm
[2025-05-01 15:21:12,013][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - num_image_token: 256
[2025-05-01 15:21:12,013][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - ps_version: v2
[2025-05-01 16:00:27,858][datasets][INFO] - PyTorch version 2.6.0 available.
