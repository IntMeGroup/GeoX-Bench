[2025-04-28 09:57:56,443][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 10:21:36,098][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 10:22:04,062][qwen_vl_utils.vision_process][INFO] - set VIDEO_TOTAL_PIXELS: 50176
[2025-04-28 10:45:41,409][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 10:46:04,885][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 10:46:04,972][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 11:36:09,562][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 11:36:34,249][transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v][INFO] - learnable separator enabled for hd transform, hd_transform_order = sub_glb
[2025-04-28 12:16:10,891][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 12:16:55,863][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-04-28 12:42:55,270][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 12:43:18,948][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 12:43:18,948][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 12:43:18,948][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 12:43:18,948][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 12:43:18,956][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 12:43:18,956][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 12:43:18,956][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 12:43:18,956][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 12:43:19,567][transformers_modules.InternVL3-8B.modeling_intern_vit][INFO] - Discovered apex.normalization.FusedRMSNorm - will use it instead of InternRMSNorm
[2025-04-28 12:43:19,571][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - num_image_token: 256
[2025-04-28 12:43:19,571][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - ps_version: v2
[2025-04-28 13:10:23,143][datasets][INFO] - PyTorch version 2.6.0 available.
