[2025-04-28 09:20:06,570][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:20:45,815][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:21:16,219][qwen_vl_utils.vision_process][INFO] - set VIDEO_TOTAL_PIXELS: 50176
[2025-04-28 09:21:25,809][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:21:49,300][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 09:21:49,379][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 09:22:09,363][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:22:34,093][transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v][INFO] - learnable separator enabled for hd transform, hd_transform_order = sub_glb
[2025-04-28 09:22:45,069][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:23:29,896][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-04-28 09:23:40,798][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:24:04,413][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 09:24:04,413][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:24:04,413][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 09:24:04,414][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 09:24:04,423][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 09:24:04,423][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:24:04,423][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 09:24:04,423][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 09:24:05,005][transformers_modules.InternVL3-8B.modeling_intern_vit][INFO] - Discovered apex.normalization.FusedRMSNorm - will use it instead of InternRMSNorm
[2025-04-28 09:24:05,008][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - num_image_token: 256
[2025-04-28 09:24:05,009][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:24:16,682][datasets][INFO] - PyTorch version 2.6.0 available.
