[2025-04-28 09:09:51,508][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:10:36,007][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:10:57,067][qwen_vl_utils.vision_process][INFO] - set VIDEO_TOTAL_PIXELS: 50176
[2025-04-28 09:11:06,841][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:11:30,303][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 09:11:30,381][transformers_modules.mPLUG-Owl3-7B-240728.configuration_mplugowl3][INFO] - vision_config is None, using default vision config
[2025-04-28 09:11:56,102][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:12:20,721][transformers_modules.Phi-3.5-vision-instruct.modeling_phi3_v][INFO] - learnable separator enabled for hd transform, hd_transform_order = sub_glb
[2025-04-28 09:12:31,681][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:13:16,565][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2025-04-28 09:13:27,757][datasets][INFO] - PyTorch version 2.6.0 available.
[2025-04-28 09:13:41,326][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 09:13:41,326][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:13:41,326][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 09:13:41,326][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 09:13:41,334][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2025-04-28 09:13:41,334][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:13:41,334][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2025-04-28 09:13:41,334][transformers_modules.InternVL3-8B.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2025-04-28 09:13:41,891][transformers_modules.InternVL3-8B.modeling_intern_vit][INFO] - Discovered apex.normalization.FusedRMSNorm - will use it instead of InternRMSNorm
[2025-04-28 09:13:41,895][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - num_image_token: 256
[2025-04-28 09:13:41,895][transformers_modules.InternVL3-8B.modeling_internvl_chat][INFO] - ps_version: v2
[2025-04-28 09:13:54,164][datasets][INFO] - PyTorch version 2.6.0 available.
